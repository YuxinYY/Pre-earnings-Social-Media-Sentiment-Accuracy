{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd80b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb436da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's not about the money, it's about sending a...</td>\n",
       "      <td>55</td>\n",
       "      <td>l6ulcx</td>\n",
       "      <td>https://v.redd.it/6j75regs72e61</td>\n",
       "      <td>6</td>\n",
       "      <td>1.611863e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:37:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "      <td>110</td>\n",
       "      <td>l6uibd</td>\n",
       "      <td>https://v.redd.it/ah50lyny62e61</td>\n",
       "      <td>23</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:32:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exit the system</td>\n",
       "      <td>0</td>\n",
       "      <td>l6uhhn</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>The CEO of NASDAQ pushed to halt trading “to g...</td>\n",
       "      <td>2021-01-28 21:30:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>29</td>\n",
       "      <td>l6ugk6</td>\n",
       "      <td>https://sec.report/Document/0001193125-21-019848/</td>\n",
       "      <td>74</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:28:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not to distract from GME, just thought our AMC...</td>\n",
       "      <td>71</td>\n",
       "      <td>l6ufgy</td>\n",
       "      <td>https://i.redd.it/4h2sukb662e61.jpg</td>\n",
       "      <td>156</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:26:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53182</th>\n",
       "      <td>What I Learned Investigating SAVA FUD Spreaders</td>\n",
       "      <td>238</td>\n",
       "      <td>owd2pn</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>87</td>\n",
       "      <td>1.627906e+09</td>\n",
       "      <td>***TLDR: Three bitter scientists partnered up ...</td>\n",
       "      <td>2021-08-02 15:03:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53183</th>\n",
       "      <td>Daily Popular Tickers Thread for August 02, 20...</td>\n",
       "      <td>228</td>\n",
       "      <td>owd1a5</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>1070</td>\n",
       "      <td>1.627906e+09</td>\n",
       "      <td>\\nYour daily hype thread. Please keep the shit...</td>\n",
       "      <td>2021-08-02 15:01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53184</th>\n",
       "      <td>Hitler reacts to the market being irrational</td>\n",
       "      <td>7398</td>\n",
       "      <td>owc5dr</td>\n",
       "      <td>https://v.redd.it/46jxu074exe71</td>\n",
       "      <td>372</td>\n",
       "      <td>1.627902e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-08-02 13:59:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53185</th>\n",
       "      <td>Daily Discussion Thread for August 02, 2021</td>\n",
       "      <td>338</td>\n",
       "      <td>owbfjf</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>11688</td>\n",
       "      <td>1.627898e+09</td>\n",
       "      <td>Your daily trading discussion thread. Please k...</td>\n",
       "      <td>2021-08-02 13:00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53186</th>\n",
       "      <td>Fraternal Association of Gambling Gentlemen an...</td>\n",
       "      <td>40</td>\n",
       "      <td>owaqd6</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>810</td>\n",
       "      <td>1.627895e+09</td>\n",
       "      <td>This is an old Yacht Club thread. Click /u/Vis...</td>\n",
       "      <td>2021-08-02 12:00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53187 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  score      id  \\\n",
       "0      It's not about the money, it's about sending a...     55  l6ulcx   \n",
       "1      Math Professor Scott Steiner says the numbers ...    110  l6uibd   \n",
       "2                                        Exit the system      0  l6uhhn   \n",
       "3      NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...     29  l6ugk6   \n",
       "4      Not to distract from GME, just thought our AMC...     71  l6ufgy   \n",
       "...                                                  ...    ...     ...   \n",
       "53182    What I Learned Investigating SAVA FUD Spreaders    238  owd2pn   \n",
       "53183  Daily Popular Tickers Thread for August 02, 20...    228  owd1a5   \n",
       "53184       Hitler reacts to the market being irrational   7398  owc5dr   \n",
       "53185        Daily Discussion Thread for August 02, 2021    338  owbfjf   \n",
       "53186  Fraternal Association of Gambling Gentlemen an...     40  owaqd6   \n",
       "\n",
       "                                                     url  comms_num  \\\n",
       "0                        https://v.redd.it/6j75regs72e61          6   \n",
       "1                        https://v.redd.it/ah50lyny62e61         23   \n",
       "2      https://www.reddit.com/r/wallstreetbets/commen...         47   \n",
       "3      https://sec.report/Document/0001193125-21-019848/         74   \n",
       "4                    https://i.redd.it/4h2sukb662e61.jpg        156   \n",
       "...                                                  ...        ...   \n",
       "53182  https://www.reddit.com/r/wallstreetbets/commen...         87   \n",
       "53183  https://www.reddit.com/r/wallstreetbets/commen...       1070   \n",
       "53184                    https://v.redd.it/46jxu074exe71        372   \n",
       "53185  https://www.reddit.com/r/wallstreetbets/commen...      11688   \n",
       "53186  https://www.reddit.com/r/wallstreetbets/commen...        810   \n",
       "\n",
       "            created                                               body  \\\n",
       "0      1.611863e+09                                                NaN   \n",
       "1      1.611862e+09                                                NaN   \n",
       "2      1.611862e+09  The CEO of NASDAQ pushed to halt trading “to g...   \n",
       "3      1.611862e+09                                                NaN   \n",
       "4      1.611862e+09                                                NaN   \n",
       "...             ...                                                ...   \n",
       "53182  1.627906e+09  ***TLDR: Three bitter scientists partnered up ...   \n",
       "53183  1.627906e+09  \\nYour daily hype thread. Please keep the shit...   \n",
       "53184  1.627902e+09                                                NaN   \n",
       "53185  1.627898e+09  Your daily trading discussion thread. Please k...   \n",
       "53186  1.627895e+09  This is an old Yacht Club thread. Click /u/Vis...   \n",
       "\n",
       "                 timestamp  \n",
       "0      2021-01-28 21:37:41  \n",
       "1      2021-01-28 21:32:10  \n",
       "2      2021-01-28 21:30:35  \n",
       "3      2021-01-28 21:28:57  \n",
       "4      2021-01-28 21:26:56  \n",
       "...                    ...  \n",
       "53182  2021-08-02 15:03:27  \n",
       "53183  2021-08-02 15:01:03  \n",
       "53184  2021-08-02 13:59:35  \n",
       "53185  2021-08-02 13:00:16  \n",
       "53186  2021-08-02 12:00:14  \n",
       "\n",
       "[53187 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is only a sample data of wallstreetbets downloaded from kaggle; not so complete\n",
    "df_comments = pd.read_csv(r\"G:\\Interview Projects\\reddit\\reddit_wsb.csv\")\n",
    "df_comments\n",
    "\n",
    "len(df_comments[(df_comments['body'].isna()==False) & (df_comments['body'].str.contains('', flags = re.IGNORECASE)) & ((pd.to_datetime(df_comments['timestamp']) >= \"2021-06-01\") & (pd.to_datetime(df_comments['timestamp']) <= \"2021-07-26\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b76cc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'AAL',\n",
       " 'AAP',\n",
       " 'AAPL',\n",
       " 'ABBV',\n",
       " 'ABC',\n",
       " 'ABMD',\n",
       " 'ABT',\n",
       " 'ACN',\n",
       " 'ADBE',\n",
       " 'ADI',\n",
       " 'ADM',\n",
       " 'ADP',\n",
       " 'ADSK',\n",
       " 'AEE',\n",
       " 'AEP',\n",
       " 'AES',\n",
       " 'AFL',\n",
       " 'AIG',\n",
       " 'AIZ',\n",
       " 'AJG',\n",
       " 'AKAM',\n",
       " 'ALB',\n",
       " 'ALGN',\n",
       " 'ALK',\n",
       " 'ALL',\n",
       " 'ALLE',\n",
       " 'ALXN',\n",
       " 'AMAT',\n",
       " 'AMCR',\n",
       " 'AMD',\n",
       " 'AME',\n",
       " 'AMGN',\n",
       " 'AMP',\n",
       " 'AMT',\n",
       " 'AMZN',\n",
       " 'ANET',\n",
       " 'ANSS',\n",
       " 'ANTM',\n",
       " 'AON',\n",
       " 'AOS',\n",
       " 'APA',\n",
       " 'APD',\n",
       " 'APH',\n",
       " 'APTV',\n",
       " 'ARE',\n",
       " 'ATO',\n",
       " 'ATVI',\n",
       " 'AVB',\n",
       " 'AVGO',\n",
       " 'AVY',\n",
       " 'AWK',\n",
       " 'AXP',\n",
       " 'AZO',\n",
       " 'BA',\n",
       " 'BAC',\n",
       " 'BAX',\n",
       " 'BBY',\n",
       " 'BDX',\n",
       " 'BEN',\n",
       " 'BF.B',\n",
       " 'BIIB',\n",
       " 'BIO',\n",
       " 'BK',\n",
       " 'BKNG',\n",
       " 'BKR',\n",
       " 'BLK',\n",
       " 'BLL',\n",
       " 'BMY',\n",
       " 'BR',\n",
       " 'BRK.B',\n",
       " 'BSX',\n",
       " 'BWA',\n",
       " 'BXP',\n",
       " 'C',\n",
       " 'CAG',\n",
       " 'CAH',\n",
       " 'CARR',\n",
       " 'CAT',\n",
       " 'CB',\n",
       " 'CBOE',\n",
       " 'CBRE',\n",
       " 'CCI',\n",
       " 'CCL',\n",
       " 'CDNS',\n",
       " 'CDW',\n",
       " 'CE',\n",
       " 'CERN',\n",
       " 'CF',\n",
       " 'CFG',\n",
       " 'CHD',\n",
       " 'CHRW',\n",
       " 'CHTR',\n",
       " 'CI',\n",
       " 'CINF',\n",
       " 'CL',\n",
       " 'CLX',\n",
       " 'CMA',\n",
       " 'CMCSA',\n",
       " 'CME',\n",
       " 'CMG',\n",
       " 'CMI',\n",
       " 'CMS',\n",
       " 'CNC',\n",
       " 'CNP',\n",
       " 'COF',\n",
       " 'COG',\n",
       " 'COO',\n",
       " 'COP',\n",
       " 'COST',\n",
       " 'CPB',\n",
       " 'CPRT',\n",
       " 'CRL',\n",
       " 'CRM',\n",
       " 'CSCO',\n",
       " 'CSX',\n",
       " 'CTAS',\n",
       " 'CTLT',\n",
       " 'CTSH',\n",
       " 'CTVA',\n",
       " 'CTXS',\n",
       " 'CVS',\n",
       " 'CVX',\n",
       " 'CZR',\n",
       " 'D',\n",
       " 'DAL',\n",
       " 'DD',\n",
       " 'DE',\n",
       " 'DFS',\n",
       " 'DG',\n",
       " 'DGX',\n",
       " 'DHI',\n",
       " 'DHR',\n",
       " 'DIS',\n",
       " 'DISCA',\n",
       " 'DISCK',\n",
       " 'DISH',\n",
       " 'DLR',\n",
       " 'DLTR',\n",
       " 'DOV',\n",
       " 'DOW',\n",
       " 'DPZ',\n",
       " 'DRE',\n",
       " 'DRI',\n",
       " 'DTE',\n",
       " 'DUK',\n",
       " 'DVA',\n",
       " 'DVN',\n",
       " 'DXC',\n",
       " 'DXCM',\n",
       " 'EA',\n",
       " 'EBAY',\n",
       " 'ECL',\n",
       " 'ED',\n",
       " 'EFX',\n",
       " 'EIX',\n",
       " 'EL',\n",
       " 'EMN',\n",
       " 'EMR',\n",
       " 'ENPH',\n",
       " 'EOG',\n",
       " 'EQIX',\n",
       " 'EQR',\n",
       " 'ES',\n",
       " 'ESS',\n",
       " 'ETN',\n",
       " 'ETR',\n",
       " 'ETSY',\n",
       " 'EVRG',\n",
       " 'EW',\n",
       " 'EXC',\n",
       " 'EXPD',\n",
       " 'EXPE',\n",
       " 'EXR',\n",
       " 'F',\n",
       " 'FANG',\n",
       " 'FAST',\n",
       " 'FB',\n",
       " 'FBHS',\n",
       " 'FCX',\n",
       " 'FDX',\n",
       " 'FE',\n",
       " 'FFIV',\n",
       " 'FIS',\n",
       " 'FISV',\n",
       " 'FITB',\n",
       " 'FLT',\n",
       " 'FMC',\n",
       " 'FOX',\n",
       " 'FOXA',\n",
       " 'FRC',\n",
       " 'FRT',\n",
       " 'FTNT',\n",
       " 'FTV',\n",
       " 'GD',\n",
       " 'GE',\n",
       " 'GILD',\n",
       " 'GIS',\n",
       " 'GL',\n",
       " 'GLW',\n",
       " 'GM',\n",
       " 'GNRC',\n",
       " 'GOOG',\n",
       " 'GOOGL',\n",
       " 'GPC',\n",
       " 'GPN',\n",
       " 'GPS',\n",
       " 'GRMN',\n",
       " 'GS',\n",
       " 'GWW',\n",
       " 'HAL',\n",
       " 'HAS',\n",
       " 'HBAN',\n",
       " 'HBI',\n",
       " 'HCA',\n",
       " 'HD',\n",
       " 'HES',\n",
       " 'HIG',\n",
       " 'HII',\n",
       " 'HLT',\n",
       " 'HOLX',\n",
       " 'HON',\n",
       " 'HPE',\n",
       " 'HPQ',\n",
       " 'HRL',\n",
       " 'HSIC',\n",
       " 'HST',\n",
       " 'HSY',\n",
       " 'HUM',\n",
       " 'HWM',\n",
       " 'IBM',\n",
       " 'ICE',\n",
       " 'IDXX',\n",
       " 'IEX',\n",
       " 'IFF',\n",
       " 'ILMN',\n",
       " 'INCY',\n",
       " 'INFO',\n",
       " 'INTC',\n",
       " 'INTU',\n",
       " 'IP',\n",
       " 'IPG',\n",
       " 'IPGP',\n",
       " 'IQV',\n",
       " 'IR',\n",
       " 'IRM',\n",
       " 'ISRG',\n",
       " 'IT',\n",
       " 'ITW',\n",
       " 'IVZ',\n",
       " 'J',\n",
       " 'JBHT',\n",
       " 'JCI',\n",
       " 'JKHY',\n",
       " 'JNJ',\n",
       " 'JNPR',\n",
       " 'JPM',\n",
       " 'K',\n",
       " 'KEY',\n",
       " 'KEYS',\n",
       " 'KHC',\n",
       " 'KIM',\n",
       " 'KLAC',\n",
       " 'KMB',\n",
       " 'KMI',\n",
       " 'KMX',\n",
       " 'KO',\n",
       " 'KR',\n",
       " 'KSU',\n",
       " 'L',\n",
       " 'LB',\n",
       " 'LDOS',\n",
       " 'LEG',\n",
       " 'LEN',\n",
       " 'LH',\n",
       " 'LHX',\n",
       " 'LIN',\n",
       " 'LKQ',\n",
       " 'LLY',\n",
       " 'LMT',\n",
       " 'LNC',\n",
       " 'LNT',\n",
       " 'LOW',\n",
       " 'LRCX',\n",
       " 'LUMN',\n",
       " 'LUV',\n",
       " 'LVS',\n",
       " 'LW',\n",
       " 'LYB',\n",
       " 'LYV',\n",
       " 'MA',\n",
       " 'MAA',\n",
       " 'MAR',\n",
       " 'MAS',\n",
       " 'MCD',\n",
       " 'MCHP',\n",
       " 'MCK',\n",
       " 'MCO',\n",
       " 'MDLZ',\n",
       " 'MDT',\n",
       " 'MET',\n",
       " 'MGM',\n",
       " 'MHK',\n",
       " 'MKC',\n",
       " 'MKTX',\n",
       " 'MLM',\n",
       " 'MMC',\n",
       " 'MMM',\n",
       " 'MNST',\n",
       " 'MO',\n",
       " 'MOS',\n",
       " 'MPC',\n",
       " 'MPWR',\n",
       " 'MRK',\n",
       " 'MRO',\n",
       " 'MS',\n",
       " 'MSCI',\n",
       " 'MSFT',\n",
       " 'MSI',\n",
       " 'MTB',\n",
       " 'MTD',\n",
       " 'MU',\n",
       " 'MXIM',\n",
       " 'NCLH',\n",
       " 'NDAQ',\n",
       " 'NEE',\n",
       " 'NEM',\n",
       " 'NFLX',\n",
       " 'NI',\n",
       " 'NKE',\n",
       " 'NLOK',\n",
       " 'NLSN',\n",
       " 'NOC',\n",
       " 'NOV',\n",
       " 'NOW',\n",
       " 'NRG',\n",
       " 'NSC',\n",
       " 'NTAP',\n",
       " 'NTRS',\n",
       " 'NUE',\n",
       " 'NVDA',\n",
       " 'NVR',\n",
       " 'NWL',\n",
       " 'NWS',\n",
       " 'NWSA',\n",
       " 'NXPI',\n",
       " 'O',\n",
       " 'ODFL',\n",
       " 'OGN',\n",
       " 'OKE',\n",
       " 'OMC',\n",
       " 'ORCL',\n",
       " 'ORLY',\n",
       " 'OTIS',\n",
       " 'OXY',\n",
       " 'PAYC',\n",
       " 'PAYX',\n",
       " 'PBCT',\n",
       " 'PCAR',\n",
       " 'PEAK',\n",
       " 'PEG',\n",
       " 'PENN',\n",
       " 'PEP',\n",
       " 'PFE',\n",
       " 'PFG',\n",
       " 'PG',\n",
       " 'PGR',\n",
       " 'PH',\n",
       " 'PHM',\n",
       " 'PKG',\n",
       " 'PKI',\n",
       " 'PLD',\n",
       " 'PM',\n",
       " 'PNC',\n",
       " 'PNR',\n",
       " 'PNW',\n",
       " 'POOL',\n",
       " 'PPG',\n",
       " 'PPL',\n",
       " 'PRGO',\n",
       " 'PRU',\n",
       " 'PSA',\n",
       " 'PSX',\n",
       " 'PTC',\n",
       " 'PVH',\n",
       " 'PWR',\n",
       " 'PXD',\n",
       " 'PYPL',\n",
       " 'QCOM',\n",
       " 'QRVO',\n",
       " 'RCL',\n",
       " 'RE',\n",
       " 'REG',\n",
       " 'REGN',\n",
       " 'RF',\n",
       " 'RHI',\n",
       " 'RJF',\n",
       " 'RL',\n",
       " 'RMD',\n",
       " 'ROK',\n",
       " 'ROL',\n",
       " 'ROP',\n",
       " 'ROST',\n",
       " 'RSG',\n",
       " 'RTX',\n",
       " 'SBAC',\n",
       " 'SBUX',\n",
       " 'SCHW',\n",
       " 'SEE',\n",
       " 'SHW',\n",
       " 'SIVB',\n",
       " 'SJM',\n",
       " 'SLB',\n",
       " 'SNA',\n",
       " 'SNPS',\n",
       " 'SO',\n",
       " 'SPG',\n",
       " 'SPGI',\n",
       " 'SRE',\n",
       " 'STE',\n",
       " 'STT',\n",
       " 'STX',\n",
       " 'STZ',\n",
       " 'SWK',\n",
       " 'SWKS',\n",
       " 'SYF',\n",
       " 'SYK',\n",
       " 'SYY',\n",
       " 'T',\n",
       " 'TAP',\n",
       " 'TDG',\n",
       " 'TDY',\n",
       " 'TEL',\n",
       " 'TER',\n",
       " 'TFC',\n",
       " 'TFX',\n",
       " 'TGT',\n",
       " 'TJX',\n",
       " 'TMO',\n",
       " 'TMUS',\n",
       " 'TPR',\n",
       " 'TRMB',\n",
       " 'TROW',\n",
       " 'TRV',\n",
       " 'TSCO',\n",
       " 'TSLA',\n",
       " 'TSN',\n",
       " 'TT',\n",
       " 'TTWO',\n",
       " 'TWTR',\n",
       " 'TXN',\n",
       " 'TXT',\n",
       " 'TYL',\n",
       " 'UA',\n",
       " 'UAA',\n",
       " 'UAL',\n",
       " 'UDR',\n",
       " 'UHS',\n",
       " 'ULTA',\n",
       " 'UNH',\n",
       " 'UNM',\n",
       " 'UNP',\n",
       " 'UPS',\n",
       " 'URI',\n",
       " 'USB',\n",
       " 'V',\n",
       " 'VFC',\n",
       " 'VIAC',\n",
       " 'VLO',\n",
       " 'VMC',\n",
       " 'VNO',\n",
       " 'VRSK',\n",
       " 'VRSN',\n",
       " 'VRTX',\n",
       " 'VTR',\n",
       " 'VTRS',\n",
       " 'VZ',\n",
       " 'WAB',\n",
       " 'WAT',\n",
       " 'WBA',\n",
       " 'WDC',\n",
       " 'WEC',\n",
       " 'WELL',\n",
       " 'WFC',\n",
       " 'WHR',\n",
       " 'WLTW',\n",
       " 'WM',\n",
       " 'WMB',\n",
       " 'WMT',\n",
       " 'WRB',\n",
       " 'WRK',\n",
       " 'WST',\n",
       " 'WU',\n",
       " 'WY',\n",
       " 'WYNN',\n",
       " 'XEL',\n",
       " 'XLNX',\n",
       " 'XOM',\n",
       " 'XRAY',\n",
       " 'XYL',\n",
       " 'YUM',\n",
       " 'ZBH',\n",
       " 'ZBRA',\n",
       " 'ZION',\n",
       " 'ZTS']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of stocks I care about\n",
    "l = pd.read_csv(r\"G:\\Interview Projects\\reddit\\S&P 500 Historical Components & Changes(07-12-2025).csv\")\n",
    "l = l[(pd.to_datetime(l[\"date\"]) >= \"2021-01-01\") & (pd.to_datetime(l[\"date\"]) <= \"2021-06-30\") ]\n",
    "\n",
    "l = l[(pd.to_datetime(l[\"date\"])==\"2021-06-04\")]\n",
    "l\n",
    "\n",
    "my_tickers = list(l.iloc[0,1].split(','))\n",
    "my_tickers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2406acc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anya Yuxin Li\\AppData\\Local\\Temp\\ipykernel_16212\\1336122645.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matched['name'] = matched['title'].str.replace(pattern, '', flags=re.IGNORECASE, regex=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik_str</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001045810</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA CORP</td>\n",
       "      <td>NVIDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000789019</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>MICROSOFT CORP</td>\n",
       "      <td>MICROSOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000320193</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001652044</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Alphabet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001018724</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>AMAZON COM INC</td>\n",
       "      <td>AMAZONCOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>0000058492</td>\n",
       "      <td>LEG</td>\n",
       "      <td>LEGGETT &amp; PLATT INC</td>\n",
       "      <td>LEGGETT &amp; PLATT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7368</th>\n",
       "      <td>0001652044</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Alphabet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>0001754301</td>\n",
       "      <td>FOX</td>\n",
       "      <td>Fox Corp</td>\n",
       "      <td>Fox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7543</th>\n",
       "      <td>0001564708</td>\n",
       "      <td>NWS</td>\n",
       "      <td>NEWS CORP</td>\n",
       "      <td>NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760</th>\n",
       "      <td>0001336917</td>\n",
       "      <td>UA</td>\n",
       "      <td>Under Armour, Inc.</td>\n",
       "      <td>UnderArmour, .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cik_str ticker                title             name\n",
       "0     0001045810   NVDA          NVIDIA CORP           NVIDIA\n",
       "1     0000789019   MSFT       MICROSOFT CORP        MICROSOFT\n",
       "2     0000320193   AAPL           Apple Inc.           Apple.\n",
       "3     0001652044  GOOGL        Alphabet Inc.        Alphabet.\n",
       "4     0001018724   AMZN       AMAZON COM INC        AMAZONCOM\n",
       "...          ...    ...                  ...              ...\n",
       "2408  0000058492    LEG  LEGGETT & PLATT INC  LEGGETT & PLATT\n",
       "7368  0001652044   GOOG        Alphabet Inc.        Alphabet.\n",
       "7499  0001754301    FOX             Fox Corp              Fox\n",
       "7543  0001564708    NWS            NEWS CORP             NEWS\n",
       "7760  0001336917     UA   Under Armour, Inc.   UnderArmour, .\n",
       "\n",
       "[461 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load security names from sec\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "url = \"https://www.sec.gov/files/company_tickers.json\"\n",
    "resp = requests.get(url, headers={\"User-Agent\": \"YuxinLi (yl14490@nyu.edu)\"})\n",
    "data = resp.json()\n",
    "\n",
    "df_map = pd.DataFrame.from_dict(data, orient=\"index\")\n",
    "\n",
    "df_map[\"cik_str\"] = df_map[\"cik_str\"].astype(str).str.zfill(10)\n",
    "\n",
    "matched = df_map[df_map['ticker'].isin(my_tickers)]\n",
    "\n",
    "words_to_remove = ['inc', '.', 'corp']\n",
    "pattern = r'\\b(' + '|'.join(words_to_remove) + r')\\b'\n",
    "\n",
    "matched['name'] = matched['title'].str.replace(pattern, '', flags=re.IGNORECASE, regex=True)\n",
    "matched.to_csv(\"matched_stocks.csv\",index = False)\n",
    "matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a78964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "stocks = list(matched['ticker'])\n",
    "api_key = \"VD06QPJ2QAT8LHD0\"\n",
    "results = []\n",
    "\n",
    "for ticker in stocks:\n",
    "    url = f\"https://www.alphavantage.co/query?function=EARNINGS&symbol={ticker}&apikey={api_key}\"\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "\n",
    "    # results.append(data)\n",
    "\n",
    "    if \"quarterlyEarnings\" in data:\n",
    "        for q in data[\"quarterlyEarnings\"]:\n",
    "            fiscal_end = q.get(\"fiscalDateEnding\")\n",
    "            reported = q.get(\"reportedDate\")\n",
    "            actual_eps = q.get(\"reportedEPS\")\n",
    "            est_eps = q.get(\"estimatedEPS\")\n",
    "            surprise = q.get(\"surprise\")\n",
    "            surprise_pct = q.get(\"surprisePercentage\")\n",
    "\n",
    "            results.append({\n",
    "                \"ticker\": ticker,\n",
    "                \"fiscalDateEnding\": fiscal_end,\n",
    "                \"reportedDate\": reported,\n",
    "                \"reportedEPS\": actual_eps,\n",
    "                \"estimatedEPS\": est_eps,\n",
    "                \"surprise\": surprise,\n",
    "                \"surprisePercentage\": surprise_pct\n",
    "            })\n",
    "\n",
    "\n",
    "        #     if fiscal_end == \"2021-06-30\":\n",
    "        #         results.append({\n",
    "        #             \"ticker\": ticker,\n",
    "        #             \"fiscalDateEnding\": fiscal_end,\n",
    "        #             \"reportedDate\": reported,\n",
    "        #             \"reportedEPS\": actual_eps,\n",
    "        #             \"estimatedEPS\": est_eps,\n",
    "        #             \"surprise\": surprise,\n",
    "        #             \"surprisePercentage\": surprise_pct\n",
    "        #         })\n",
    "    print(f\"Done: {ticker}\")\n",
    "    time.sleep(1) \n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    # print(df_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed2cf9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>fiscalDateEnding</th>\n",
       "      <th>reportedDate</th>\n",
       "      <th>reportedEPS</th>\n",
       "      <th>estimatedEPS</th>\n",
       "      <th>surprise</th>\n",
       "      <th>surprisePercentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>5.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>3.2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>2025-02-26</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>5.2134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>9.4595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.6300</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>7.9365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48330</th>\n",
       "      <td>UA</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.0400</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>75.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48331</th>\n",
       "      <td>UA</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>-0.0100</td>\n",
       "      <td>-4.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48332</th>\n",
       "      <td>UA</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>20.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48333</th>\n",
       "      <td>UA</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>2016-07-26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>-0.0100</td>\n",
       "      <td>-50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48334</th>\n",
       "      <td>UA</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48335 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ticker fiscalDateEnding reportedDate  reportedEPS  estimatedEPS  \\\n",
       "0       NVDA       2025-07-31   2025-08-27         1.05        1.0000   \n",
       "1       NVDA       2025-04-30   2025-05-28         0.96        0.9300   \n",
       "2       NVDA       2025-01-31   2025-02-26         0.89        0.8459   \n",
       "3       NVDA       2024-10-31   2024-11-20         0.81        0.7400   \n",
       "4       NVDA       2024-07-31   2024-08-28         0.68        0.6300   \n",
       "...      ...              ...          ...          ...           ...   \n",
       "48330     UA       2017-03-31   2017-04-27        -0.01       -0.0400   \n",
       "48331     UA       2016-12-31   2017-01-31         0.23        0.2400   \n",
       "48332     UA       2016-09-30   2016-10-25         0.29        0.2400   \n",
       "48333     UA       2016-06-30   2016-07-26         0.01        0.0200   \n",
       "48334     UA       2016-03-31   2016-04-21         0.04        0.0200   \n",
       "\n",
       "       surprise  surprisePercentage  \n",
       "0        0.0500              5.0000  \n",
       "1        0.0300              3.2258  \n",
       "2        0.0441              5.2134  \n",
       "3        0.0700              9.4595  \n",
       "4        0.0500              7.9365  \n",
       "...         ...                 ...  \n",
       "48330    0.0300             75.0000  \n",
       "48331   -0.0100             -4.1667  \n",
       "48332    0.0500             20.8333  \n",
       "48333   -0.0100            -50.0000  \n",
       "48334    0.0200            100.0000  \n",
       "\n",
       "[48335 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_results.to_csv(\"earningreleasedatesandsurprises.csv\",index=False)\n",
    "df_results = pd.read_csv(r\"G:\\Interview Projects\\reddit\\earningreleasedatesandsurprises.csv\")\n",
    "\n",
    "df_results['fiscalDateEnding'] = pd.to_datetime(df_results['fiscalDateEnding'])\n",
    "df_results['reportedDate'] = pd.to_datetime(df_results['reportedDate'])\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "770c171f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>fiscalDateEnding</th>\n",
       "      <th>reportedDate</th>\n",
       "      <th>reportedEPS</th>\n",
       "      <th>estimatedEPS</th>\n",
       "      <th>surprise</th>\n",
       "      <th>surprisePercentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.9608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>2.170</td>\n",
       "      <td>1.920</td>\n",
       "      <td>0.250</td>\n",
       "      <td>13.0208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>1.300</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.290</td>\n",
       "      <td>28.7129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>1.360</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.400</td>\n",
       "      <td>41.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-29</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.140</td>\n",
       "      <td>22.5806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48065</th>\n",
       "      <td>LEG</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.120</td>\n",
       "      <td>22.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48183</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>1.360</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.400</td>\n",
       "      <td>41.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48229</th>\n",
       "      <td>FOX</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48264</th>\n",
       "      <td>NWS</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-08-05</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.100</td>\n",
       "      <td>166.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48313</th>\n",
       "      <td>UA</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ticker fiscalDateEnding reportedDate  reportedEPS  estimatedEPS  \\\n",
       "16      NVDA       2021-07-31   2021-08-18        0.104         0.102   \n",
       "122     MSFT       2021-06-30   2021-07-27        2.170         1.920   \n",
       "240     AAPL       2021-06-30   2021-07-27        1.300         1.010   \n",
       "358    GOOGL       2021-06-30   2021-07-27        1.360         0.960   \n",
       "442     AMZN       2021-06-30   2021-07-29        0.760         0.620   \n",
       "...      ...              ...          ...          ...           ...   \n",
       "48065    LEG       2021-06-30   2021-08-02        0.660         0.540   \n",
       "48183   GOOG       2021-06-30   2021-07-27        1.360         0.960   \n",
       "48229    FOX       2021-06-30   2021-08-04        0.650         0.650   \n",
       "48264    NWS       2021-06-30   2021-08-05        0.160         0.060   \n",
       "48313     UA       2021-06-30   2021-08-03        0.100         0.050   \n",
       "\n",
       "       surprise  surprisePercentage  \n",
       "16        0.002              1.9608  \n",
       "122       0.250             13.0208  \n",
       "240       0.290             28.7129  \n",
       "358       0.400             41.6667  \n",
       "442       0.140             22.5806  \n",
       "...         ...                 ...  \n",
       "48065     0.120             22.2222  \n",
       "48183     0.400             41.6667  \n",
       "48229     0.000              0.0000  \n",
       "48264     0.100            166.6667  \n",
       "48313     0.050            100.0000  \n",
       "\n",
       "[461 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[df_results['reportedDate'].dt.month.isin([6, 7, 8]) & (df_results['reportedDate'].dt.year==2021)]\n",
    "# df_results[df_results['ticker']=='A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "174a895c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>fiscalDateEnding</th>\n",
       "      <th>reportedDate</th>\n",
       "      <th>reportedEPS</th>\n",
       "      <th>estimatedEPS</th>\n",
       "      <th>surprise</th>\n",
       "      <th>surprisePercentage</th>\n",
       "      <th>window_start</th>\n",
       "      <th>window_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>2021-08-17</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11.1111</td>\n",
       "      <td>2021-07-17</td>\n",
       "      <td>2021-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3121</td>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>2021-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAP</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-08-24</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.36</td>\n",
       "      <td>11.8421</td>\n",
       "      <td>2021-07-24</td>\n",
       "      <td>2021-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.29</td>\n",
       "      <td>28.7129</td>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>2021-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-30</td>\n",
       "      <td>3.09</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>YUM</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-29</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>20.8333</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>2021-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.6043</td>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>2021-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11.4634</td>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>2021-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>ZION</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.77</td>\n",
       "      <td>58.7786</td>\n",
       "      <td>2021-06-19</td>\n",
       "      <td>2021-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-08-05</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>10.1852</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>2021-08-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker fiscalDateEnding reportedDate  reportedEPS  estimatedEPS  surprise  \\\n",
       "0        A       2021-07-31   2021-08-17         1.10          0.99      0.11   \n",
       "1      AAL       2021-06-30   2021-07-22        -1.69         -1.73      0.04   \n",
       "2      AAP       2021-06-30   2021-08-24         3.40          3.04      0.36   \n",
       "3     AAPL       2021-06-30   2021-07-27         1.30          1.01      0.29   \n",
       "4     ABBV       2021-06-30   2021-07-30         3.09          3.09      0.00   \n",
       "..     ...              ...          ...          ...           ...       ...   \n",
       "456    YUM       2021-06-30   2021-07-29         1.16          0.96      0.20   \n",
       "457    ZBH       2021-06-30   2021-08-03         1.90          1.87      0.03   \n",
       "458   ZBRA       2021-06-30   2021-08-03         4.57          4.10      0.47   \n",
       "459   ZION       2021-06-30   2021-07-19         2.08          1.31      0.77   \n",
       "460    ZTS       2021-06-30   2021-08-05         1.19          1.08      0.11   \n",
       "\n",
       "     surprisePercentage window_start window_end  \n",
       "0               11.1111   2021-07-17 2021-08-16  \n",
       "1                2.3121   2021-06-22 2021-07-21  \n",
       "2               11.8421   2021-07-24 2021-08-23  \n",
       "3               28.7129   2021-06-27 2021-07-26  \n",
       "4                0.0000   2021-06-30 2021-07-29  \n",
       "..                  ...          ...        ...  \n",
       "456             20.8333   2021-06-29 2021-07-28  \n",
       "457              1.6043   2021-07-03 2021-08-02  \n",
       "458             11.4634   2021-07-03 2021-08-02  \n",
       "459             58.7786   2021-06-19 2021-07-18  \n",
       "460             10.1852   2021-07-05 2021-08-04  \n",
       "\n",
       "[461 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "earnings_df = df_results.copy()\n",
    "# type(earnings_df['reportedDate'][0])\n",
    "earnings_df = earnings_df[(pd.to_datetime(earnings_df['reportedDate']) >= \"2021-01-01\") & (pd.to_datetime(earnings_df['reportedDate']) < \"2021-12-31\") ]\n",
    "nth_rank = 2\n",
    "\n",
    "new = (\n",
    "    earnings_df.sort_values([\"ticker\", \"reportedDate\"]).groupby(\"ticker\").apply(lambda x: x.iloc[nth_rank] if len(x) > nth_rank else None).reset_index(drop=True)\n",
    ")\n",
    "new['reportedDate'] = pd.to_datetime(new['reportedDate'])\n",
    "new['window_start'] = new['reportedDate'].apply(lambda x: x - relativedelta(months=1))\n",
    "new['window_end'] = new['reportedDate'].apply(lambda x: x - relativedelta(days=1))\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce72cb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'author', 'created_utc', 'score', 'subreddit', 'title',\n",
       "       'selftext', 'num_comments', 'url', 'upvote_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_comments = pd.read_csv(r\"G:\\Interview Projects\\reddit\\test.csv\")\n",
    "df_comments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154eda43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "50346    False\n",
       "50347    False\n",
       "50348    False\n",
       "50349    False\n",
       "50350    False\n",
       "Length: 50351, dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the relevant stocks of each comment\n",
    "# submission & comment data\n",
    "df_comments = pd.read_csv(r\"G:\\Interview Projects\\reddit\\test.csv\")\n",
    "df_comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d010c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "def create_stock_patterns(df_stocks):\n",
    "    stock_patterns = {}\n",
    "    \n",
    "    for _, row in df_stocks.iterrows():\n",
    "        ticker = row['ticker']\n",
    "        name = row['name']\n",
    "        title = row['title']\n",
    "        \n",
    "        patterns = set()\n",
    "        \n",
    "        # Add ticker symbol\n",
    "        patterns.add(ticker.upper())\n",
    "        \n",
    "        # Add company names\n",
    "        patterns.add(name.lower())\n",
    "        patterns.add(title.lower())\n",
    "        \n",
    "        # Remove common corporate suffixes and create variations\n",
    "        clean_name = re.sub(r'\\b(inc\\.?|corp\\.?|corporation|company|co\\.?|ltd\\.?)\\b', '', name.lower()).strip()\n",
    "        clean_title = re.sub(r'\\b(inc\\.?|corp\\.?|corporation|company|co\\.?|ltd\\.?)\\b', '', title.lower()).strip()\n",
    "        \n",
    "        patterns.add(clean_name)\n",
    "        patterns.add(clean_title)\n",
    "        \n",
    "        # Add common abbreviations/nicknames (you'll need to build this)\n",
    "        nickname_map = {\n",
    "            'AAPL': ['apple'],\n",
    "            'MSFT': ['microsoft', 'msft'],\n",
    "            'GOOGL': ['google', 'alphabet'],\n",
    "            'AMZN': ['amazon'],\n",
    "            'NVDA': ['nvidia'],\n",
    "            # Add more as needed\n",
    "        }\n",
    "        \n",
    "        if ticker in nickname_map:\n",
    "            patterns.update(nickname_map[ticker])\n",
    "        \n",
    "        stock_patterns[ticker] = list(patterns)\n",
    "    \n",
    "    return stock_patterns\n",
    "\n",
    "def fast_stock_mentions(text, stock_patterns):\n",
    "    \"\"\"\n",
    "    Much faster approach - exact matching only\n",
    "    \"\"\"\n",
    "    text_upper = text.upper()\n",
    "    text_lower = text.lower()\n",
    "    mentions = []\n",
    "    \n",
    "    for ticker, patterns in stock_patterns.items():\n",
    "        # Quick ticker check first\n",
    "        if re.search(r'\\b' + re.escape(ticker) + r'\\b', text_upper):\n",
    "            mentions.append({\n",
    "                'ticker': ticker,\n",
    "                'match_type': 'exact_ticker',\n",
    "                'confidence': 100\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Quick substring check for names\n",
    "        for pattern in patterns:\n",
    "            if pattern.lower() in text_lower:\n",
    "                mentions.append({\n",
    "                    'ticker': ticker,\n",
    "                    'match_type': 'exact_name', \n",
    "                    'confidence': 95\n",
    "                })\n",
    "                break\n",
    "    \n",
    "    return mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e1fb2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_stock_mentions(text, stock_patterns, min_similarity=80):\n",
    "    \"\"\"\n",
    "    Find stock mentions using multiple matching strategies\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    mentions = []\n",
    "    \n",
    "    for ticker, patterns in stock_patterns.items():\n",
    "        # Level 1: Exact ticker match (case-insensitive)\n",
    "        if re.search(r'\\b' + re.escape(ticker) + r'\\b', text, re.IGNORECASE):\n",
    "            mentions.append({\n",
    "                'ticker': ticker,\n",
    "                'match_type': 'exact_ticker',\n",
    "                'confidence': 100\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Level 2: Exact name match\n",
    "        for pattern in patterns:\n",
    "            if pattern in text_lower:\n",
    "                mentions.append({\n",
    "                    'ticker': ticker,\n",
    "                    'match_type': 'exact_name',\n",
    "                    'confidence': 95\n",
    "                })\n",
    "                break\n",
    "        \n",
    "        # Level 3: Fuzzy matching\n",
    "        words = text_lower.split()\n",
    "        for pattern in patterns:\n",
    "            for word in words:\n",
    "                similarity = fuzz.ratio(pattern, word)\n",
    "                if similarity >= min_similarity:\n",
    "                    mentions.append({\n",
    "                        'ticker': ticker,\n",
    "                        'match_type': 'fuzzy',\n",
    "                        'confidence': similarity\n",
    "                    })\n",
    "                    break\n",
    "    \n",
    "    return mentions\n",
    "\n",
    "def smart_stock_mentions(text, stock_patterns):\n",
    "    \"\"\"\n",
    "    Match stocks with smart ticker handling\n",
    "    \"\"\"\n",
    "    mentions = []\n",
    "    text_upper = text.upper()\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    for ticker, patterns in stock_patterns.items():\n",
    "        found = False\n",
    "        \n",
    "        # 1. Safe ticker matching (3+ chars or non-common words)\n",
    "        for safe_ticker in patterns['safe_tickers']:\n",
    "            if re.search(r'\\b' + re.escape(safe_ticker) + r'\\b', text_upper):\n",
    "                mentions.append({\n",
    "                    'ticker': ticker,\n",
    "                    'match_type': 'safe_ticker',\n",
    "                    'confidence': 100\n",
    "                })\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if found:\n",
    "            continue\n",
    "            \n",
    "        # 2. Context-required tickers (like $A, or \"buy A stock\")\n",
    "        for risky_ticker in patterns['require_context']:\n",
    "            # Look for $ prefix\n",
    "            if re.search(r'\\$' + re.escape(risky_ticker) + r'\\b', text_upper):\n",
    "                mentions.append({\n",
    "                    'ticker': ticker,\n",
    "                    'match_type': 'ticker_with_context',\n",
    "                    'confidence': 95\n",
    "                })\n",
    "                found = True\n",
    "                break\n",
    "            \n",
    "            # Look for stock context words nearby\n",
    "            stock_context_pattern = rf'\\b(?:stock|ticker|symbol|share|buy|sell|hold)\\s+{re.escape(risky_ticker)}\\b|\\b{re.escape(risky_ticker)}\\s+(?:stock|ticker|symbol|share|up|down|calls|puts)\\b'\n",
    "            if re.search(stock_context_pattern, text_upper):\n",
    "                mentions.append({\n",
    "                    'ticker': ticker,\n",
    "                    'match_type': 'ticker_with_context',\n",
    "                    'confidence': 90\n",
    "                })\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if found:\n",
    "            continue\n",
    "            \n",
    "        # 3. Company name matching\n",
    "        for company_name in patterns['company_names']:\n",
    "            if len(company_name) > 3 and company_name.lower() in text_lower:\n",
    "                mentions.append({\n",
    "                    'ticker': ticker,\n",
    "                    'match_type': 'company_name',\n",
    "                    'confidence': 85\n",
    "                })\n",
    "                break\n",
    "    \n",
    "    return mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bac6da6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enhanced_patterns(df_stocks):\n",
    "    \"\"\"\n",
    "    Create more sophisticated patterns including common slang/nicknames\n",
    "    \"\"\"\n",
    "    \n",
    "    # Common stock market slang/nicknames\n",
    "    slang_map = {\n",
    "        'TSLA': ['tesla', 'elon', 'musk'],\n",
    "        'GME': ['gamestop', 'gme', 'game stop'],\n",
    "        'AMC': ['amc', 'movie theater'],\n",
    "        'AAPL': ['apple', 'iphone', 'tim cook'],\n",
    "        'MSFT': ['microsoft', 'bill gates'],\n",
    "        'AMZN': ['amazon', 'bezos', 'aws'],\n",
    "        'META': ['facebook', 'meta', 'zuckerberg', 'fb'],\n",
    "        'GOOGL': ['google', 'alphabet', 'search'],\n",
    "        'NVDA': ['nvidia', 'gpu', 'graphics'],\n",
    "        # Add more based on your specific data\n",
    "    }\n",
    "    \n",
    "    stock_patterns = {}\n",
    "    for _, row in df_stocks.iterrows():\n",
    "        ticker = row['ticker']\n",
    "        patterns = []\n",
    "        \n",
    "        # Basic patterns\n",
    "        patterns.extend([ticker, row['name'].lower(), row['title'].lower()])\n",
    "        \n",
    "        # Add slang if available\n",
    "        if ticker in slang_map:\n",
    "            patterns.extend(slang_map[ticker])\n",
    "        \n",
    "        # Clean patterns (remove duplicates, empty strings)\n",
    "        patterns = list(set([p.strip() for p in patterns if p.strip()]))\n",
    "        stock_patterns[ticker] = patterns\n",
    "    \n",
    "    return stock_patterns\n",
    "\n",
    "def analyze_stock_mentions_fast(df_social, stock_patterns, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Process in batches with progress tracking and include all essential fields\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total_rows = len(df_social)\n",
    "    \n",
    "    # Define essential fields\n",
    "    essential_fields = [\n",
    "        'id', 'title', 'selftext', 'author', 'created_utc', 'score', \n",
    "        'num_comments', 'url', 'subreddit', 'upvote_ratio'\n",
    "    ]\n",
    "    \n",
    "    for i in range(0, total_rows, batch_size):\n",
    "        batch = df_social.iloc[i:i+batch_size]\n",
    "        print(f\"Processing batch {i//batch_size + 1}/{(total_rows-1)//batch_size + 1}\")\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            text = str(row.get('selftext', '')) + ' ' + str(row.get('title', ''))\n",
    "            mentions = fast_stock_mentions(text, stock_patterns)  # Use fast version\n",
    "            \n",
    "            # Create base record with all essential fields\n",
    "            base_record = {}\n",
    "            for field in essential_fields:\n",
    "                base_record[field] = row.get(field, None)\n",
    "            \n",
    "            for mention in mentions:\n",
    "                # Create a complete record for each mention\n",
    "                record = base_record.copy()  # Copy all the essential fields\n",
    "                \n",
    "                # Add stock mention specific fields\n",
    "                record.update({\n",
    "                    'ticker': mention['ticker'],\n",
    "                    'match_type': mention['match_type'],\n",
    "                    'confidence': mention['confidence']\n",
    "                })\n",
    "                \n",
    "                results.append(record)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "648b6b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_smart_stock_patterns(df_stocks):\n",
    "    \"\"\"\n",
    "    Create patterns with smart ticker filtering\n",
    "    \"\"\"\n",
    "    # Define problematic tickers that shouldn't be matched\n",
    "    SKIP_TICKERS = {\n",
    "        'A',     # Too common as article\n",
    "        'I',     # Too common as pronoun  \n",
    "        'AM',    # Common word \"am\"\n",
    "        'AN',    # Common word \"an\"\n",
    "        'AS',    # Common word \"as\"\n",
    "        'AT',    # Common word \"at\"\n",
    "        'BE',    # Common word \"be\" \n",
    "        'BY',    # Common word \"by\"\n",
    "        'DO',    # Common word \"do\"\n",
    "        'GO',    # Common word \"go\"\n",
    "        'HE',    # Common word \"he\"\n",
    "        'IF',    # Common word \"if\"\n",
    "        'IN',    # Common word \"in\"\n",
    "        'IS',    # Common word \"is\"\n",
    "        'IT',    # Common word \"it\"\n",
    "        'MY',    # Common word \"my\"\n",
    "        'NO',    # Common word \"no\"\n",
    "        'OF',    # Common word \"of\"\n",
    "        'ON',    # Common word \"on\"\n",
    "        'OR',    # Common word \"or\"\n",
    "        'SO',    # Common word \"so\"\n",
    "        'TO',    # Common word \"to\"\n",
    "        'UP',    # Common word \"up\"\n",
    "        'US',    # Common word \"us\"\n",
    "        'WE',    # Common word \"we\"\n",
    "        # Add more as needed\n",
    "    }\n",
    "    \n",
    "    # Minimum length for ticker matching\n",
    "    MIN_TICKER_LENGTH = 2\n",
    "    \n",
    "    stock_patterns = {}\n",
    "    \n",
    "    for _, row in df_stocks.iterrows():\n",
    "        ticker = row['ticker'].upper()\n",
    "        name = row['name']\n",
    "        title = row['title']\n",
    "        \n",
    "        patterns = {\n",
    "            'safe_tickers': [],      # Tickers safe to match\n",
    "            'company_names': [],     # Company name variations\n",
    "            'require_context': []    # Tickers that need context (like \"$A\")\n",
    "        }\n",
    "        \n",
    "        # Handle ticker matching\n",
    "        if ticker in SKIP_TICKERS:\n",
    "            # For problematic tickers, only match with $ prefix or clear stock context\n",
    "            patterns['require_context'].append(ticker)\n",
    "        elif len(ticker) >= MIN_TICKER_LENGTH:\n",
    "            patterns['safe_tickers'].append(ticker)\n",
    "        \n",
    "        # Add company names (cleaned)\n",
    "        clean_name = re.sub(r'\\b(inc\\.?|corp\\.?|corporation|company|co\\.?|ltd\\.?)\\b', '', name, flags=re.IGNORECASE).strip()\n",
    "        clean_title = re.sub(r'\\b(inc\\.?|corp\\.?|corporation|company|co\\.?|ltd\\.?)\\b', '', title, flags=re.IGNORECASE).strip()\n",
    "        \n",
    "        patterns['company_names'].extend([name, title, clean_name, clean_title])\n",
    "        \n",
    "        # Remove empty/short names\n",
    "        patterns['company_names'] = [n for n in patterns['company_names'] if len(n.strip()) > 2]\n",
    "        \n",
    "        stock_patterns[ticker] = patterns\n",
    "    \n",
    "    return stock_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8de6f207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik_str</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>name</th>\n",
       "      <th>fiscalDateEnding</th>\n",
       "      <th>reportedDate</th>\n",
       "      <th>reportedEPS</th>\n",
       "      <th>estimatedEPS</th>\n",
       "      <th>surprise</th>\n",
       "      <th>surprisePercentage</th>\n",
       "      <th>window_start</th>\n",
       "      <th>window_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001045810</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA CORP</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.9608</td>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>2021-08-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000789019</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>MICROSOFT CORP</td>\n",
       "      <td>MICROSOFT</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>2.170</td>\n",
       "      <td>1.920</td>\n",
       "      <td>0.250</td>\n",
       "      <td>13.0208</td>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>2021-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000320193</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Apple.</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>1.300</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.290</td>\n",
       "      <td>28.7129</td>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>2021-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001652044</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Alphabet.</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>1.360</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.400</td>\n",
       "      <td>41.6667</td>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>2021-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001018724</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>AMAZON COM INC</td>\n",
       "      <td>AMAZONCOM</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-29</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.140</td>\n",
       "      <td>22.5806</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>2021-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0000058492</td>\n",
       "      <td>LEG</td>\n",
       "      <td>LEGGETT &amp; PLATT INC</td>\n",
       "      <td>LEGGETT &amp; PLATT</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.120</td>\n",
       "      <td>22.2222</td>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>2021-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0001652044</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Alphabet.</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>1.360</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.400</td>\n",
       "      <td>41.6667</td>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>2021-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0001754301</td>\n",
       "      <td>FOX</td>\n",
       "      <td>Fox Corp</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>2021-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0001564708</td>\n",
       "      <td>NWS</td>\n",
       "      <td>NEWS CORP</td>\n",
       "      <td>NEWS</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-08-05</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.100</td>\n",
       "      <td>166.6667</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>2021-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0001336917</td>\n",
       "      <td>UA</td>\n",
       "      <td>Under Armour, Inc.</td>\n",
       "      <td>UnderArmour, .</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>2021-08-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cik_str ticker                title             name fiscalDateEnding  \\\n",
       "0    0001045810   NVDA          NVIDIA CORP           NVIDIA       2021-07-31   \n",
       "1    0000789019   MSFT       MICROSOFT CORP        MICROSOFT       2021-06-30   \n",
       "2    0000320193   AAPL           Apple Inc.           Apple.       2021-06-30   \n",
       "3    0001652044  GOOGL        Alphabet Inc.        Alphabet.       2021-06-30   \n",
       "4    0001018724   AMZN       AMAZON COM INC        AMAZONCOM       2021-06-30   \n",
       "..          ...    ...                  ...              ...              ...   \n",
       "455  0000058492    LEG  LEGGETT & PLATT INC  LEGGETT & PLATT       2021-06-30   \n",
       "456  0001652044   GOOG        Alphabet Inc.        Alphabet.       2021-06-30   \n",
       "457  0001754301    FOX             Fox Corp              Fox       2021-06-30   \n",
       "458  0001564708    NWS            NEWS CORP             NEWS       2021-06-30   \n",
       "459  0001336917     UA   Under Armour, Inc.   UnderArmour, .       2021-06-30   \n",
       "\n",
       "    reportedDate  reportedEPS  estimatedEPS  surprise  surprisePercentage  \\\n",
       "0     2021-08-18        0.104         0.102     0.002              1.9608   \n",
       "1     2021-07-27        2.170         1.920     0.250             13.0208   \n",
       "2     2021-07-27        1.300         1.010     0.290             28.7129   \n",
       "3     2021-07-27        1.360         0.960     0.400             41.6667   \n",
       "4     2021-07-29        0.760         0.620     0.140             22.5806   \n",
       "..           ...          ...           ...       ...                 ...   \n",
       "455   2021-08-02        0.660         0.540     0.120             22.2222   \n",
       "456   2021-07-27        1.360         0.960     0.400             41.6667   \n",
       "457   2021-08-04        0.650         0.650     0.000              0.0000   \n",
       "458   2021-08-05        0.160         0.060     0.100            166.6667   \n",
       "459   2021-08-03        0.100         0.050     0.050            100.0000   \n",
       "\n",
       "    window_start window_end  \n",
       "0     2021-07-18 2021-08-17  \n",
       "1     2021-06-27 2021-07-26  \n",
       "2     2021-06-27 2021-07-26  \n",
       "3     2021-06-27 2021-07-26  \n",
       "4     2021-06-29 2021-07-28  \n",
       "..           ...        ...  \n",
       "455   2021-07-02 2021-08-01  \n",
       "456   2021-06-27 2021-07-26  \n",
       "457   2021-07-04 2021-08-03  \n",
       "458   2021-07-05 2021-08-04  \n",
       "459   2021-07-03 2021-08-02  \n",
       "\n",
       "[460 rows x 12 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matching eps data with stocks' names\n",
    "results = pd.merge(matched, new, on = \"ticker\", how = \"inner\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b462e746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>url</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>npgy6l</td>\n",
       "      <td>TheMarkIII</td>\n",
       "      <td>1622505919</td>\n",
       "      <td>1</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Caught a glimpse of AMC on its way to the moon!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://i.redd.it/tuw6d5qlpj271.jpg</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nph22g</td>\n",
       "      <td>macfern</td>\n",
       "      <td>1622506236</td>\n",
       "      <td>1</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Wanda Group Fully Withdraws From AMC in Nearly...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.google.com/amp/s/www.theepochtimes...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nph34u</td>\n",
       "      <td>randyzmzzzz</td>\n",
       "      <td>1622506330</td>\n",
       "      <td>1</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>AMC at 42nd street, NYC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://i.redd.it/9i2q5u6tqj271.jpg</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nph718</td>\n",
       "      <td>TheHighness1</td>\n",
       "      <td>1622506662</td>\n",
       "      <td>1</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Ape Strong together</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://i.redd.it/fzn8646trj271.jpg</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nph8m3</td>\n",
       "      <td>wowwkwkssiw</td>\n",
       "      <td>1622506792</td>\n",
       "      <td>1</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Elon Musk Charged With Second Degree Murder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://theproffessionalbroker.blogspot.com/20...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50346</th>\n",
       "      <td>pfhn3d</td>\n",
       "      <td>_disguy</td>\n",
       "      <td>1630452959</td>\n",
       "      <td>2117</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>GME has consistently spiked every T-17 days be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.0</td>\n",
       "      <td>https://i.redd.it/zhjf7do34sk71.png</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50347</th>\n",
       "      <td>pfhpj2</td>\n",
       "      <td>Kobeblackmambattv</td>\n",
       "      <td>1630453193</td>\n",
       "      <td>75</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>$GENI DD | I'm either a $GENIus or a retard. 2...</td>\n",
       "      <td>&amp;amp;#x200B;\\n\\nhttps://preview.redd.it/bfclvu...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50348</th>\n",
       "      <td>pfhq3j</td>\n",
       "      <td>poohyawn</td>\n",
       "      <td>1630453246</td>\n",
       "      <td>2</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Does anyone know what the first stock symbol i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>https://i.redd.it/4jomom135sk71.jpg</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50349</th>\n",
       "      <td>pfhtyf</td>\n",
       "      <td>outphase84</td>\n",
       "      <td>1630453627</td>\n",
       "      <td>2</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>1.4K to 7.1K overnight on FIVN puts. Thanks ZM!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>https://i.redd.it/3drt4ft76sk71.jpg</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50350</th>\n",
       "      <td>pfhw6s</td>\n",
       "      <td>outphase84</td>\n",
       "      <td>1630453851</td>\n",
       "      <td>82</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>1.4K to 7.K overnight on FIVN puts. Thanks ZM!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>https://www.reddit.com/gallery/pfhw6s</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50351 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             author  created_utc  score       subreddit  \\\n",
       "0      npgy6l         TheMarkIII   1622505919      1  wallstreetbets   \n",
       "1      nph22g            macfern   1622506236      1  wallstreetbets   \n",
       "2      nph34u        randyzmzzzz   1622506330      1  wallstreetbets   \n",
       "3      nph718       TheHighness1   1622506662      1  wallstreetbets   \n",
       "4      nph8m3        wowwkwkssiw   1622506792      1  wallstreetbets   \n",
       "...       ...                ...          ...    ...             ...   \n",
       "50346  pfhn3d            _disguy   1630452959   2117  wallstreetbets   \n",
       "50347  pfhpj2  Kobeblackmambattv   1630453193     75  wallstreetbets   \n",
       "50348  pfhq3j           poohyawn   1630453246      2  wallstreetbets   \n",
       "50349  pfhtyf         outphase84   1630453627      2  wallstreetbets   \n",
       "50350  pfhw6s         outphase84   1630453851     82  wallstreetbets   \n",
       "\n",
       "                                                   title  \\\n",
       "0       Caught a glimpse of AMC on its way to the moon!!   \n",
       "1      Wanda Group Fully Withdraws From AMC in Nearly...   \n",
       "2                                AMC at 42nd street, NYC   \n",
       "3                                    Ape Strong together   \n",
       "4            Elon Musk Charged With Second Degree Murder   \n",
       "...                                                  ...   \n",
       "50346  GME has consistently spiked every T-17 days be...   \n",
       "50347  $GENI DD | I'm either a $GENIus or a retard. 2...   \n",
       "50348  Does anyone know what the first stock symbol i...   \n",
       "50349    1.4K to 7.1K overnight on FIVN puts. Thanks ZM!   \n",
       "50350     1.4K to 7.K overnight on FIVN puts. Thanks ZM!   \n",
       "\n",
       "                                                selftext  num_comments  \\\n",
       "0                                                    NaN           1.0   \n",
       "1                                                    NaN           1.0   \n",
       "2                                                    NaN           1.0   \n",
       "3                                                    NaN           1.0   \n",
       "4                                                    NaN           1.0   \n",
       "...                                                  ...           ...   \n",
       "50346                                                NaN         252.0   \n",
       "50347  &amp;#x200B;\\n\\nhttps://preview.redd.it/bfclvu...          45.0   \n",
       "50348                                                NaN          14.0   \n",
       "50349                                                NaN           2.0   \n",
       "50350                                                NaN          35.0   \n",
       "\n",
       "                                                     url  upvote_ratio  \n",
       "0                    https://i.redd.it/tuw6d5qlpj271.jpg          1.00  \n",
       "1      https://www.google.com/amp/s/www.theepochtimes...          1.00  \n",
       "2                    https://i.redd.it/9i2q5u6tqj271.jpg          1.00  \n",
       "3                    https://i.redd.it/fzn8646trj271.jpg          1.00  \n",
       "4      https://theproffessionalbroker.blogspot.com/20...          1.00  \n",
       "...                                                  ...           ...  \n",
       "50346                https://i.redd.it/zhjf7do34sk71.png          0.93  \n",
       "50347  https://www.reddit.com/r/wallstreetbets/commen...          0.89  \n",
       "50348                https://i.redd.it/4jomom135sk71.jpg          0.61  \n",
       "50349                https://i.redd.it/3drt4ft76sk71.jpg          1.00  \n",
       "50350              https://www.reddit.com/gallery/pfhw6s          0.90  \n",
       "\n",
       "[50351 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0709ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/51\n",
      "Processing batch 2/51\n",
      "Processing batch 3/51\n",
      "Processing batch 4/51\n",
      "Processing batch 5/51\n",
      "Processing batch 6/51\n",
      "Processing batch 7/51\n",
      "Processing batch 8/51\n",
      "Processing batch 9/51\n",
      "Processing batch 10/51\n",
      "Processing batch 11/51\n",
      "Processing batch 12/51\n",
      "Processing batch 13/51\n",
      "Processing batch 14/51\n",
      "Processing batch 15/51\n",
      "Processing batch 16/51\n",
      "Processing batch 17/51\n",
      "Processing batch 18/51\n",
      "Processing batch 19/51\n",
      "Processing batch 20/51\n",
      "Processing batch 21/51\n",
      "Processing batch 22/51\n",
      "Processing batch 23/51\n",
      "Processing batch 24/51\n",
      "Processing batch 25/51\n",
      "Processing batch 26/51\n",
      "Processing batch 27/51\n",
      "Processing batch 28/51\n",
      "Processing batch 29/51\n",
      "Processing batch 30/51\n",
      "Processing batch 31/51\n",
      "Processing batch 32/51\n",
      "Processing batch 33/51\n",
      "Processing batch 34/51\n",
      "Processing batch 35/51\n",
      "Processing batch 36/51\n",
      "Processing batch 37/51\n",
      "Processing batch 38/51\n",
      "Processing batch 39/51\n",
      "Processing batch 40/51\n",
      "Processing batch 41/51\n",
      "Processing batch 42/51\n",
      "Processing batch 43/51\n",
      "Processing batch 44/51\n",
      "Processing batch 45/51\n",
      "Processing batch 46/51\n",
      "Processing batch 47/51\n",
      "Processing batch 48/51\n",
      "Processing batch 49/51\n",
      "Processing batch 50/51\n",
      "Processing batch 51/51\n",
      "Found 56131 mentions\n"
     ]
    }
   ],
   "source": [
    "# Use only exact matching\n",
    "# stock_patterns = create_enhanced_patterns(results)  # Your existing function\n",
    "stock_patterns = create_smart_stock_patterns(results) #this avoids fuzzy match of tickers on certain frequently used words\n",
    "\n",
    "# Test on just 100 rows first\n",
    "# sample_df = df_comments.head(100)\n",
    "# mentions_df = analyze_stock_mentions_fast(sample_df, stock_patterns)\n",
    "\n",
    "mentions_df = analyze_stock_mentions_fast(df_comments, stock_patterns)\n",
    "print(f\"Found {len(mentions_df)} mentions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a152d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1622505919\n",
       "1        1622507119\n",
       "2        1622507134\n",
       "3        1622507134\n",
       "4        1622507137\n",
       "            ...    \n",
       "56126    1630453193\n",
       "56127    1630453193\n",
       "56128    1630453193\n",
       "56129    1630453246\n",
       "56130    1630453851\n",
       "Name: created_utc, Length: 56131, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions_df['created_utc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b88c21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_utc_dt(x):\n",
    "    # Accepts int/float epoch or string/datetime; returns timezone-aware UTC datetime\n",
    "    if pd.isna(x):\n",
    "        return pd.NaT\n",
    "    if isinstance(x, (int, float, np.integer, np.floating)):\n",
    "        return pd.to_datetime(int(x), unit=\"s\", utc=True)\n",
    "    dt = pd.to_datetime(x, utc=True, errors=\"coerce\")\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b28887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matching every relement submission/comment data with the stock's 2021 Q2 earnings\n",
    "\n",
    "results = pd.merge(mentions_df, new[new['reportedDate'].dt.month.isin([6, 7, 8]) & (new['reportedDate'].dt.year==2021)], on = 'ticker', how = \"inner\")\n",
    "results.to_csv(r\"G:\\Interview Projects\\reddit\\completeset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c86ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(r\"G:\\Interview Projects\\reddit\\completeset.csv\")\n",
    "results['created_utc'] = results['created_utc'].apply(lambda x: to_utc_dt(x))\n",
    "results['reportedDate'] = pd.to_datetime(results['reportedDate'])\n",
    "results = results[results['created_utc'] < results['reportedDate'].dt.tz_localize('UTC')]\n",
    "\n",
    "results.to_csv(r\"G:\\Interview Projects\\reddit\\trainingdata.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the main part: start to conduct sentiment analysis\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta, timezone\n",
    "from collections import defaultdict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
